<!DOCTYPE html><html lang="en" mode="light" > <!-- The Head v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>An undocumented aspect of the uops cache miss granularity on Skylake microarchitecture. | Dmitrii Bundin</title><meta name="generator" content="Jekyll v4.0.0" /><meta property="og:title" content="An undocumented aspect of the uops cache miss granularity on Skylake microarchitecture." /><meta name="author" content="Dmitrii Bundin" /><meta property="og:locale" content="en_US" /><meta name="description" content="Introduction" /><meta property="og:description" content="Introduction" /><link rel="canonical" href="https://dmitriibundin.github.io/posts/uop-cache-miss-granularity/" /><meta property="og:url" content="https://dmitriibundin.github.io/posts/uop-cache-miss-granularity/" /><meta property="og:site_name" content="Dmitrii Bundin" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-05-16T04:30:46+03:00" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"mainEntityOfPage":{"@type":"WebPage","@id":"https://dmitriibundin.github.io/posts/uop-cache-miss-granularity/"},"@type":"BlogPosting","url":"https://dmitriibundin.github.io/posts/uop-cache-miss-granularity/","author":{"@type":"Person","name":"Dmitrii Bundin"},"headline":"An undocumented aspect of the uops cache miss granularity on Skylake microarchitecture.","dateModified":"2020-05-16T04:30:46+03:00","datePublished":"2020-05-16T04:30:46+03:00","description":"Introduction","@context":"https://schema.org"}</script> <!-- The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps Generated by: https://www.favicon-generator.org/ v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT license --><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="preload" as="style" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin><link rel="preload" as="style" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="preload" as="style" href="/assets/css/post.css"><link rel="stylesheet" href="/assets/css/post.css"><link rel="preload" as="style" href="/assets/lib/bootstrap-toc-1.0.1/bootstrap-toc.min.css"><link rel="stylesheet" href="/assets/lib/bootstrap-toc-1.0.1/bootstrap-toc.min.css" /><link rel="preload" as="script" href="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"><link rel="preload" as="script" href="https://cdn.jsdelivr.net/npm/popper.js@1.15.0/dist/umd/popper.min.js" integrity="sha256-fTuUgtT7O2rqoImwjrhDgbXTKUwyxxujIMRIK7TbuNU=" crossorigin> <script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script> <script> window.jQuery || document.write('<script src="/assets/lib/jquery-3.4.1.min.js"><\/script>'); </script> <script src="https://cdn.jsdelivr.net/npm/popper.js@1.15.0/dist/umd/popper.min.js" integrity="sha256-fTuUgtT7O2rqoImwjrhDgbXTKUwyxxujIMRIK7TbuNU=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" integrity="sha256-5+02zu5UULQkO7w1GIr6vftCgMfFdZcAHeDtFnKZsBs=" crossorigin="anonymous" async></script> <script src="/assets/js/dist/commons.js" async></script> <script src="/assets/js/dist/timeago.min.js" async></script><link rel="preload" as="script" href="/assets/lib/bootstrap-toc-1.0.1/bootstrap-toc.min.js"> <script src="/assets/lib/bootstrap-toc-1.0.1/bootstrap-toc.min.js" async></script> <script src="/assets/js/dist/toc.min.js" async></script> <script src="/assets/js/dist/tooltip-loader.min.js" async></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column"> <!-- The Side Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="nav-wrapper"><div id="profile-wrapper" class="d-flex flex-column"><div id="avatar" class="d-flex justify-content-center"> <a href="/" alt="avatar"> <img src="/assets/img/sample/avatar.jpg" alt="avatar"> </a></div><div class="profile-text mt-3"><div id="site-title"> <a href="/">Dmitrii Bundin</a></div><div id="site-subtitle" class="font-italic">Low Level Performance Engineering</div></div></div><ul class="nav flex-column"><li class="nav-item d-flex justify-content-center "> <a href="/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-home ml-3 mr-3 unloaded"></i> <span>HOME</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/categories/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-stream ml-3 mr-3 unloaded"></i> <span>CATEGORIES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/tags/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-tags ml-3 mr-3 unloaded"></i> <span>TAGS</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/archives/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-archive ml-3 mr-3 unloaded"></i> <span>ARCHIVES</span> </a></li><li class="nav-item d-flex justify-content-center "> <a href="/tabs/about/" class="nav-link d-flex justify-content-center align-items-center w-100"> <i class="fa-fw fas fa-info ml-3 mr-3 unloaded"></i> <span>ABOUT</span> </a></li></ul></div><div class="sidebar-bottom d-flex flex-wrap justify-content-around mt-4"> <a href="https://github.com/dmitriibundin" target="_blank"> <i class="fab fa-github-alt"></i> </a> <a href="https://linkedin.com/in/dbundin" target="_blank"> <i class="fab fa-linkedin"></i> </a> <a href="javascript:window.open('mailto:' + ['dmitrii.bundin.a','gmail.com'].join('@'))"> <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" target="_blank"> <i class="fas fa-rss"></i> </a></div></div><!-- The Top Bar v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>An undocumented aspect of the uops cache miss granularity on Skylake microarchitecture.</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"> <!-- Fixed kramdown code highlight rendering: https://github.com/penibelst/jekyll-compress-html/issues/101 https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901 --><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>An undocumented aspect of the uops cache miss granularity on Skylake microarchitecture.</h1><div class="post-meta text-muted d-flex flex-column"><div> Posted <span class="timeago" data-toggle="tooltip" data-placement="bottom" title="Sat, May 16, 2020, 4:30 AM +0300"> May 16, 2020 <i class="unloaded">2020-05-16T04:30:46+03:00</i> </span> by <span class="author"> Dmitrii Bundin </span></div><div> Updated <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Sun, May 17, 2020, 3:52 AM +0300"> May 17, 2020 <i class="unloaded">2020-05-17T03:52:42+03:00</i> </span></div></div><div class="post-content"><h2 id="introduction">Introduction</h2><p>Starting Sandy Brindge microarchitecture the uops cache (a.k.a. Decoded ICache, DSB, Decode Stream Buffer) is a part of the CPU Front End and is responsible for caching microoperations of recently decoded instructions. Its primary goal is to reduce power and latency of the Front End and avoid performance bottlenecks like LCP (Length Changing Prefix) stalls which the <a href="https://software.intel.com/content/www/us/en/develop/download/intel-64-and-ia-32-architectures-optimization-reference-manual.html">Intel Architecture Optimization Manual</a> (IAOM) documents to have 3 cycles penalty.</p><p>IAOM/2.5.2.1:</p><blockquote><p>The following length changing prefixes (LCPs) imply instruction length that is different from the default length of instructions. Therefore they cause an additional penalty of three cycles per LCP during length decoding.</p></blockquote><p>The uops cache structure significantly differs from what we have in the standard instruction/data caches. IAOM provides some details about its internal organization and there are 3 important aspects to understand:</p><ul><li><p>uops cache consists of 32 sets each of which contains 8 ways. Each way in turn can hold up to 6 micro-ops allowing up to 1536 micro-ops to be cached in total.</p></li><li><p>All micro-ops in a way represent instructions which are statically contiguous in the code and have their EIPs within the same aligned 32-byte region.</p></li><li><p>Up to three ways may be dedicated to the same 32-byte aligned chunk allowing a total of 18 micro-ops to be cached per 32-byte region of the original IA program.</p></li></ul><p>The two primary sources of micro-ops in the uops cache are either Legacy Decode Pipeline or Microcode ROM. Any time an instruction is decoded and delivered to the micro-op queue, it is also delivered to the uops cache. Next time the micro-op is needed it <strong><em>might</em></strong> be delivered from the uops cache bypassing the decode stage. The key point here is that it might but also it <strong><em>might not</em></strong>. One possible reason for that may be the micro-ops belonging to a 32-byte region overflow the uops cache. Intel clearly documents the case below</p><p>IAOM/B.5.7.3:</p><blockquote><p>There are no partial hits in the Decoded ICache. If any micro-op that is part of that lookup on the 32-byte chunk is missing, a Decoded ICache miss occurs on all micro-ops for that transaction.</p></blockquote><p>Basically what we are going to do during this article is to check how the statement above works on real examples.</p><p>Before starting out the research there are 2 important facts to understand about the uops cache</p><p>IAOM/2.5.2.2:</p><ul><li><p>The Decoded ICache is virtually included in the Instruction cache</p></li><li><p>Once micro-ops are delivered from the legacy pipeline, fetching micro-ops from the Decoded ICache can resume only after the next branch micro-op</p></li></ul><p>The 2 things these rules suggest us to check are how (predicted to be taken) branches affect the microarchitectural state of the Front End and how the uops cache interacts with L1I.</p><p>Let’s go ahead and get started.</p><h2 id="drill-down-the-uops-cache">Drill down the Uops cache</h2><p>To analyze the uops cache behavior we will need routines written in the Assembly language. All of the examples below are guaranteed to be assembled by NASM version 2.13.02 and run on Intel Kaby Lake i7-8550U CPU. Basically what we are going to do is to collect performance counters provided by the Intel PMU and try to come to a sensible conclusion depending on what a particular routine does.</p><p>The counters we are interested in are <code class="highlighter-rouge">icache_64b.iftag_hit:u</code>, <code class="highlighter-rouge">idq.dsb_uops:u</code>, <code class="highlighter-rouge">idq.mite_uops:u</code> and <code class="highlighter-rouge">idq.ms_uops:u</code>. Consider each of them separately:</p><ul><li><p><code class="highlighter-rouge">icache_64b.iftag_hit</code> - As per the <a href="https://software.intel.com/content/dam/develop/public/us/en/documents/325384-sdm-vol-3abcd.pdf">Intel System Programming Manual</a> it counts “Instruction fetch tag lookups that hit in the instruction cache (L1I)”. The modern CPU caches however stores a memory address along with a cache line. The address basically consists of 3 components: offset, index and tag. The index is used to determine possible ways a line may occupy in the cache and the tag is used to check if the address is actually cached. IDK if the “Instruction fetch tag” is the same or has empty or non-empty overlapping with the address tag.</p></li><li><p><code class="highlighter-rouge">idq.dsb_uops</code> - Counts the number of micro-ops delivered from the uops cache.</p></li><li><p><code class="highlighter-rouge">idq.mite_uops</code> - Counts the number of micro-ops delivered from the Legacy Decode Pipeline</p></li><li><p><code class="highlighter-rouge">idq.ms_uops</code> - Counts the number of micro-ops delivered from Microcode Sequencer</p></li></ul><p>The <code class="highlighter-rouge">:u</code> suffix means that the counters will be collected for user code only which runs in the ring 3. It is natively supported by the Intel hardware and implemented as a dedicated bit in the <code class="highlighter-rouge">IA32_PERFEVTSEL</code> MSR. Here is how the Intel System Programming Manual depicts the <code class="highlighter-rouge">IA32_PERFEVTSEL</code> structure:</p><p><img src="/assets/img/uops-cache-miss-gran/ia32perfevtsel_layout.png" alt="upload-image" /></p><p>The <code class="highlighter-rouge">USR</code> bit corresponds to user-space counters. A counter programmed with one of the <code class="highlighter-rouge">IA32_PERFEVTSEL</code>s can later be read from the corresponding <code class="highlighter-rouge">IA32_PMC</code> MSR.</p><p>Most of the examples used in this article will be implemented as NASM macros which basically consist of a loop with iterations count specified in the <code class="highlighter-rouge">rdi</code> register. The iterations count used in the examples will be set to <code class="highlighter-rouge">1 &lt;&lt; 31</code> which seems optimal in the sense of collecting counters and time spent on running the examples. Here is how the main program entry point look like:</p><div class="highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre><td class="rouge-code"><pre>ITERATION_COUNT equ 1 &lt;&lt; 31

%macro sys_exit 1
    mov eax, 0x3C
    mov edi, %1
    syscall
%endmacro

section .text

global _start

_start:
    mov rdi, ITERATION_COUNT
    ;the macro to measure
    sys_exit 0
</pre></table></code></div></div><details> <summary>About the assembly implementation of the main entry point</summary> Initially it was implemented in C and planned to be rewritten in C++ to automate code generation using templates, but after a while it turned out to be impractical and add unnecessary complications when communicating to hand-written assembly code. </details><p>In some examples considered below we will need to count uops by hand which is done in the <strong><em>fused domain</em></strong>. It means that Macro Fused pair <code class="highlighter-rouge">dec rdi</code>, <code class="highlighter-rouge">jnz</code> will be accounted as a signle micro-op.</p><p>The source code of all the examples provided in this article is available on my <a href="https://github.com/dmitriibundin/microarch-check/tree/master/ucache-miss-granularity">GitHub repository</a>. If you find any mistakes, leaving a comment here or openinig a pull request is highly appreciated. Talk less, work more, and here is the first example:</p><h3 id="simple-fetching-from-the-uops-cache">Simple fetching from the uops cache</h3><p>To understand what’s going on when micro-ops are fetched from the uops cache we will need the following NASM macro:</p><div class="highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre>%macro nopax8_rep 1        
    %%loop:
    %rep %1                
         times 8 nop ax
    %endrep
    dec rdi
    jnz %%loop
    ret
%endmacro
</pre></table></code></div></div><p>The macro argument specifies the number of times to repeat <code class="highlighter-rouge">times 8 nop ax</code>. We have the following results:</p><p><img src="/assets/img/uops-cache-miss-gran/simple-uops-hit.png" alt="upload-image" /></p><p>The <code class="highlighter-rouge">idq.dsb_uops</code>, <code class="highlighter-rouge">idq.mite_uops</code>, <code class="highlighter-rouge">idq.ms_uops</code> are pretty expected. All of the uops are delivered from the uops cache since 8 consecutive <code class="highlighter-rouge">nop ax</code> instructions consume the entire 32-bytes region.</p><p>The insteresting thing to notice is actually on the plot of <code class="highlighter-rouge">icache_64b.iftag_hit</code>. As can be seen the instruction fetch tag hit lookup happens once per 64 bytes. The 64 bytes in turns contains 2 32-bytes instruction regions cached in the uops cache. Considering the fact that switches from <code class="highlighter-rouge">MITE</code> to <code class="highlighter-rouge">DSB</code> require a branch micro-op to be taken it is reasonable to check how the counters are affected by the unconditional <code class="highlighter-rouge">jmp</code> inserted in the middle of cache lines. This brings us to the following example:</p><h3 id="fetching-from-the-uops-cache-with-jmp">Fetching from the uops cache with jmp</h3><p>To investigate the uops cache behavior when taking unconditional branches we need slightly more complex example in terms of NASM implementation:</p><div class="highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre><td class="rouge-code"><pre>%macro nopax7jmp 1         
    %%loop:
    %define ODD
    %rep %1
        %ifdef ODD
            times 7 nop ax
            %push
            jmp %$aligned_label
            align 32
            %$aligned_label:
            %pop
            %undef ODD
        %else
            times 8 nop ax
            %define ODD
        %endif
    %endrep
    dec rdi
    jnz %%loop
    ret
%endmacro
</pre></table></code></div></div><p>What the macro <code class="highlighter-rouge">nopax7jmp</code> does is it generates blocks of assembly code. Each block comprises either <code class="highlighter-rouge">times 7 nop ax</code> following the unconditional <code class="highlighter-rouge">jmp</code> to the start of the next 32-bytes aligned region or just <code class="highlighter-rouge">times 8 nop ax</code>. The macro argument specifies the total number of such blocks to generate so that they alternate each other.</p><p>Running the example with perf we have the following results:</p><p><img src="/assets/img/uops-cache-miss-gran/uops-hits-jmp.png" alt="upload-image" /></p><p>Results depicted on the second plot meet our expectations perfectly. All of the uops are delivered from the DSB, while MITE is staying idle. Moreover the result is exactly the same as we saw in the previous example. This is because <code class="highlighter-rouge">nop ax</code> and the near jump instruction <code class="highlighter-rouge">jmp</code> are both decoded into a signle micro-op.</p><p>The key difference with the previous example can be observed on the first plot. As can be seen adding <code class="highlighter-rouge">jmp</code>s in the middle of cache lines causes additional instruction fetch tag lookup even thought the target is located within the same cache line. Recalling IAOM/2.5.2.2:</p><blockquote><p>Once micro-ops are delivered from the legacy pipeline, fetching micro-ops from the Decoded ICache can resume only after the next branch micro-op.</p></blockquote><p>we can get a direction for further steps in the research. It seems reasonable to check if MITE to DSB switches and probably DSB lookup itself are connected to the Instruction Fetch (IF) tag lookup. To get more insights consider an example where an L1I line contains a 32-bytes chunk that do not fit the DSB.</p><h3 id="overflowing-dsb-with-too-many-uops">Overflowing DSB with too many uops</h3><p>To check how the DSB behaves when micro-ops cannot fit it we can consider an example containing more then 18 consecutive <code class="highlighter-rouge">nop</code> instructions within a 32-bytes chunk. For example:</p><div class="highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre><td class="rouge-code"><pre>%macro nopax8nop19jmp 1
    %assign iteration_count %1
    align 64
    %%loop:
    %rep %1
        times 8 nop ax
        times 19 nop
        %assign iteration_count iteration_count-1
        %if iteration_count &gt; 0
            %push
                jmp %$aligned_label
                align 64
                %$aligned_label:
            %pop
       %else
            dec rdi
            jnz %%loop
       %endif
    %endrep
%endmacro
</pre></table></code></div></div><p>What we have here is each 64-bytes L1I line contains 8 <code class="highlighter-rouge">nop ax</code>s following 19 <code class="highlighter-rouge">nop</code>s ending with either <code class="highlighter-rouge">jmp</code> to the begginning of the consecutive cache line or a loop conditional branch.</p><p>Before providing the results of the experiments let’s try to imagine how they might look like. For specificity consider the <code class="highlighter-rouge">nopax8nop19jmp 2</code> macro invokation. Its code is kind of verbose, but I will provide it here with some comments added for clarity’s sake:</p><div class="highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
</pre><td class="rouge-code"><pre>;first 64-bytes aligned block start
&lt;..@2.loop&gt; nop    ax
nop    ax
nop    ax
nop    ax
nop    ax
nop    ax
nop    ax
nop    ax
;32-bytes boundary
nop
nop 
nop 
nop 
nop
nop
nop
nop
nop
nop
nop
nop
nop
nop
nop
nop
nop
nop
nop
jmp    0x400100 &lt;..@5.aligned_label&gt; ;jump to the second block start
;first block end

;nop's to meet 64-bytes alignment

;second 64-bytes aligned block start
&lt;..@5.aligned_label&gt; nop    ax
nop    ax                                                                                                                                                             
nop    ax                                                                                                                                                             
nop    ax                                                                                                                                                             
nop    ax                                                                                                                                                             
nop    ax                                                                                                                                                             
nop    ax                                                                                                                                                             
nop    ax                                                                                                                                                             
;32-bytes boundary
nop                                                                                                                                                                   
nop                                                                                                                                                                   
nop                                                                                                                                                                   
nop                                                                                                                                                                   
nop                                                                                                                                                                   
nop                                                                                                                                                                   
nop                                                                                                                                                                   
nop                                                                                                                                                                   
nop                                                                                                                                                                   
nop                                                                                                                                                                   
nop                                                                                                                                                                   
nop                                                                                                                                                                   
nop                                                                                                                                                                   
nop                                                                                                                                                                   
nop                                                                                                                                                                   
nop                                                                                                                                                                   
nop                                                                                                                                                                   
nop                                                                                                                                                                   
nop                                                                                                                                                                   
dec    rdi                                                                                                                                                            
jne    0x4000c0 &lt;..@2.loop&gt; 
;second block end
</pre></table></code></div></div><p>The 19 <code class="highlighter-rouge">nop</code>s at the end of each cache line do not fit the DSB so switching to the Legacy Decode Pipeline should occur and all of the micro-ops should be delivered from there. Having <code class="highlighter-rouge">jmp</code> to the next cache line right after the 19 <code class="highlighter-rouge">nop</code>s and taking IAOM/2.5.5.2</p><blockquote><p>Once micro-ops are delivered from the legacy pipeline, fetching micro-ops from the Decoded ICache can resume only after the next branch micro-op</p></blockquote><p>into account it seems reasonable to assume that all of the 8 <code class="highlighter-rouge">nop ax</code>s each 64-bytes region starts with should be delivered from the DSB.</p><p>Now let’s take a look at what the actual results are:</p><p><img src="/assets/img/uops-cache-miss-gran/dsb-ovf-full-line-miss-iftag.png" alt="upload-image" /></p><p><img src="/assets/img/uops-cache-miss-gran/dsb-ovf-full-line-miss-uops.png" alt="upload-image" /></p><p>The result does not meer our expectation. The most interesting thing here is that the number of uops delivered from the DSB were exactly 0. In all cases. It means that all of the uops were delivered from MITE. Now recall the IAOM/B.5.7.3:</p><blockquote><p>There are no partial hits in the Decoded ICache. If any micro-op that is part of that lookup on the 32-byte chunk is missing, a Decoded ICache miss occurs on all micro-ops for that transaction.</p></blockquote><p>The example shown above suggests that the miss might happen not just for 32-byte lookup but for the whole cache line. To better understand conditions under which such misses may occur we need to consider a few more examples.</p><h3 id="partial-dsb-hits-per-32-bytes-region">Partial DSB hits per 32-bytes region</h3><p>Now lets take a look at an example with slightly different structure that we have worked with before.</p><div class="highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre>%macro iftag_granularity_miss 1
    align 64
    %%loop:
    times %1 nop
    jmp %%next_instruction
    %%next_instruction:
    %assign ucache_rest_space 30 - %1
    times ucache_rest_space nop
    times 32 nop
    dec rdi
    jnz %%loop
%endmacro
</pre></table></code></div></div><p>The principal thing to notice about the macro is that it contais <code class="highlighter-rouge">jmp</code> somewhere in the middle of the first 32-bytes region of a cache line. The <code class="highlighter-rouge">jmp</code> instruction itself was artificially inserted to research the impact of taken branches on the DSB misses. Basically what we have here is <code class="highlighter-rouge">nop</code> repeated <code class="highlighter-rouge">n</code> times where <code class="highlighter-rouge">n</code> varies between 0 and 30 inclusively. The <code class="highlighter-rouge">nop</code>s follow <code class="highlighter-rouge">jmp</code> jumping to the exactly next insruction so it does not change any control flow. After the <code class="highlighter-rouge">jmp</code> there there are <code class="highlighter-rouge">nop</code>s till the end of the cache line. At the very beginning of the next cache line there is a loop conditional branch.</p><p>Now let’s take a look a the results, but only for <code class="highlighter-rouge">18 &lt;= n &lt;= 30</code> at first :</p><p><img src="/assets/img/uops-cache-miss-gran/partial-miss-all-uops.png" alt="upload-image" /></p><p>The result is expected. The first 32-byte region clearly overflows the DSB since it contains 31 micro-ops in total. But why did I consider the results starting 18? To understand it let’s take a look at the whole result set of the experiment:</p><p><img src="/assets/img/uops-cache-miss-gran/partial-hits-uops.png" alt="upload-image" /></p><p>It is kind of surprising, isn’t it? We clearely have a partial hit per 32-bytes region here. Recalling how DSB caches micro-ops the result for 17 and below might become clearer. Having 17 <code class="highlighter-rouge">nop</code>s and 1 <code class="highlighter-rouge">jmp</code> gives us 18 micro ops in total. The DSB is allowed to use at most 3 ways per 32-bytes region each of which can hold at most 6 micro-ops. It allows no more then 18 micro-ops to be cached per 32-bytes region. And this is exactly the number we have in the experiment.</p><p>Recalling that branches predicted to be taken require Instruction Fetch Tag lookup and combining all the experiments that have been run so far I came to the following emprical observation:</p><blockquote><p><strong>There is no partial hit per the largest region that does not require Instruction Fetch Tag lookup. It may be either cache line boundaries or branches predicted to be taken.</strong></p></blockquote><p>Unfortunately it is difficult to predict the actual amount of uops delivered from DSB in such cases. As was shown on the previous plot the DSB delivery rate was highly non-linear depending on the number of uops.</p><p>So to check if the observation does not break when coming to more-or-less non trivial cases let’s consider the following:</p><h2 id="example">Example</h2><div class="highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre><td class="rouge-code"><pre>example_fun:
    align 64
    times 8 nop ax
    .loop:
    times 4 nop ax
    test edi, 0x1
    jnz .no_fetch_start
    times 2 nop ax
    .cache_line_boundary:                 ;This label indicates 64-byte boundary
    times 2 nop ax
    nop dword [eax + 1 * eax + 0x1] 
    jmp .loop_branch
    .no_fetch_start:                      ;Starting this point micro-ops are not
                                          ;expected to be fetched from the DSB 
                                          ;till the end of the cache line
    times 4 nop ax
    .32bytes_boundary:                    ;This label indicates 32-byte boundary
                                          ;within the cache line
    times 6 nop ax
    nop dword [eax + 1 * eax + 0x1] 
    jmp .loop_branch
    .loop_branch:                         ;Indicates a loop conditional branch
                                          ;Also a 64-byte boundary
    dec rdi
    jnz .loop
    ret

</pre></table></code></div></div><p>What the function does is it checks if the current value in <code class="highlighter-rouge">rdi</code> is even or odd and in case if it’s even the control flow jumps to the <code class="highlighter-rouge">.no_fetch_start</code> label. The region this label defines spans 2 32-bytes regions within the same cache line. The most import thing about it is that the second 32-bytes part is ended with the branch micro-op. There is a <a href="https://www.intel.com/content/dam/support/us/en/documents/processors/mitigations-jump-conditional-code-erratum.pdf">jcc erratum</a> stating that if 32-bytes region ends with a jump micro op then the whole region misses the DSB. And that’s exactly what we are going to check here. The second 32-bytes part of the <code class="highlighter-rouge">.no_fetch_start</code> region misses due to the erratum and applying our emperical observation we can state that the part starting the <code class="highlighter-rouge">.no_fetch_start</code> label till the 32-bytes boundary will miss as well.</p><p>The expected number of MITE micro-ops would look like</p><div class="highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>Expected MITE uops = (1L &lt;&lt; 31) / 2 * 12 = 12,884,901,888
</pre></table></code></div></div><p>The formula needs some explanation. The reason for division by 2 was that the control flow jumps to the <code class="highlighter-rouge">.no_fetch_start</code> label every 2 iterations (there was the <code class="highlighter-rouge">test edi, 0x1</code> instruction before). Summing up all the micro-ops in the region starting from <code class="highlighter-rouge">.no_fetch_start</code> we have</p><div class="highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre>times 4 nop ax +
times 6 nop ax +
nop dword [eax + 1 * eax + 0x1] +
jmp .loop_branch = 4 + 6 + 1 + 1 = 12
</pre></table></code></div></div><p>Recalling that the iteration count was defined to be <code class="highlighter-rouge">1L &lt;&lt; 31</code> we have exactly the formula above.</p><p>Now let’s run it under perf event and take a look at the actual results:</p><div class="highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre>Performance counter stats for './bin':

     6 435 798 367      icache_64b.iftag_hit:u
    19 186 853 013      idq.dsb_uops:u
    12 988 209 611      idq.mite_uops:u
     9 751 861 923      cycles

       2,462670271 seconds time elapsed

       2,462579000 seconds user
       0,000000000 seconds sys
</pre></table></code></div></div><p>Our expectation is very close to the result reported by perf events: <code class="highlighter-rouge">12 884 901 888</code> vs <code class="highlighter-rouge">12 988 209 611</code>.</p><h2 id="conclusion">Conclusion</h2><p>The uops cache is clearly documented in the Intel Software Optimization Manual, but there are nuances:</p><ul><li><p>At least on <strong>Kaby Lake i7-8550U</strong> uops cannot be delivered from the DSB if any of them cannot fit it within the Instruction Fetch Tag boundary. The boundary may be defined with either a branch micro-op or a cache line end.</p></li><li><p>Even though uops may hit the DSB within the IF Tag boundary it is difficult to predict how many of them will actually be delivered from it (See <a href="#partial-dsb-hits-per-32-byte-region">the example above</a>)</p></li><li><p>All of the examples above contain no more than 1 taken branches per cache line. If there are 2 or more things get much more unpredictable so it is difficult to give a reasonable estimation even in simple cases. This is what I still how no idea about.</p></li></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/cpu/'>CPU</a>, <a href='/categories/frontend/'>FrontEnd</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/x86/" class="post-tag no-text-decoration" >x86</a> <a href="/tags/uops-cache/" class="post-tag no-text-decoration" >uops-cache</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><!-- Post sharing snippet v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=An undocumented aspect of the uops cache miss granularity on Skylake microarchitecture. - Dmitrii Bundin&url=https://dmitriibundin.github.io/posts/uop-cache-miss-granularity/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=An undocumented aspect of the uops cache miss granularity on Skylake microarchitecture. - Dmitrii Bundin&u=https://dmitriibundin.github.io/posts/uop-cache-miss-granularity/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=An undocumented aspect of the uops cache miss granularity on Skylake microarchitecture. - Dmitrii Bundin&url=https://dmitriibundin.github.io/posts/uop-cache-miss-granularity/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><!-- The Pannel on right side (Desktop views) v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"><h3 data-toc-skip>Recent Update</h3><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/uop-cache-miss-granularity/">An undocumented aspect of the uops cache miss granularity on Skylake microarchitecture.</a></li></ul></div><div id="access-tags"><h3 data-toc-skip>Trending Tags</h3><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <!-- The trending tags list v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung MIT Licensed --> <a class="post-tag" href="/tags/x86/">x86</a> <a class="post-tag" href="/tags/uops-cache/">uops cache</a></div></div></div><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><h3 data-toc-skip class="pl-3 pt-2 mb-3">Contents</h3><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div id="post-extend-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"> <!-- Navigation buttons at the bottom of the post. v2.1 https://github.com/cotes2020/jekyll-theme-chirpy © 2020 Cotes Chung MIT License --><div class="post-navigation d-flex justify-content-between"> <span class="btn btn-outline-primary disabled"><p>-</p></span> <span class="btn btn-outline-primary disabled"><p>-</p></span></div><!-- The Disqus lazy loading. Powered by: https://osvaldas.info/lazy-loading-disqus-comments v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung MIT License --><div id="disqus" class="pt-2 pb-4"><p class="font-italic text-muted small">Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script src="/assets/lib/jquery.disqusloader.min.js"></script> <script> var options = { scriptUrl: '//dmitriibundin.disqus.com/embed.js', disqusConfig: function() { this.page.url = 'https://dmitriibundin.github.io/posts/uop-cache-miss-granularity/'; this.page.identifier = '/posts/uop-cache-miss-granularity/'; } }; $.disqusLoader('#disqus', options); </script> <!-- The related posts of current post. Placed in the bottom of every single post. v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung Published under the MIT License --></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const el = document.querySelectorAll('#post-wrapper img'); const observer = lozad(el); observer.observe(); </script> <!-- The Footer v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2020 <a href="https://github.com/username">Dmitrii Bundin</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy/">Chirpy</a> theme.</p></div></div></footer></div><!-- The Search results v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-xl-11 post-content"><div id="search-hints"><h4 class="text-muted">Trending Tags</h4><!-- The trending tags list v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2019 Cotes Chung MIT Licensed --> <a class="post-tag" href="/tags/x86/">x86</a> <a class="post-tag" href="/tags/uops-cache/">uops cache</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <!-- The GA snippet v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','https://www.google-analytics.com/analytics.js','ga'); ga('create', '', 'auto'); ga('send', 'pageview'); </script> <!-- Jekyll Simple Search loader v2.0 https://github.com/cotes2020/jekyll-theme-chirpy © 2017-2019 Cotes Chung MIT License --> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js" integrity="sha256-qcLR00zq6pJk4je3MLgAri8Nn+ZumUlXgTKR2H/xCY0=" crossorigin="anonymous"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://dmitriibundin.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"><div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>{categories}</div><div><i class="fa fa-tag fa-fw"></i>{tags}</div></div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>' }); </script>
